Model selected: {'checkpoint_info': {'filename': 'F:\\03_Gen AI tools\\webui_forge_cu121_torch231\\webui\\models\\Stable-diffusion\\flux\\flux1DevHyperNF4Flux1DevBNB_flux1DevHyperNF4.safetensors', 'hash': 'a005585e'}, 'additional_modules': [], 'unet_storage_dtype': None}
Using online LoRAs in FP16: False
Model selected: {'checkpoint_info': {'filename': 'F:\\03_Gen AI tools\\webui_forge_cu121_torch231\\webui\\models\\Stable-diffusion\\flux\\flux1DevHyperNF4Flux1DevBNB_flux1DevHyperNF4.safetensors', 'hash': 'a005585e'}, 'additional_modules': [], 'unet_storage_dtype': None}
Using online LoRAs in FP16: True
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\uvicorn\protocols\http\h11_impl.py", line 404, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\uvicorn\middleware\proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\fastapi\applications.py", line 1106, in __call__
    await super().__call__(scope, receive, send)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\starlette\applications.py", line 122, in __call__
    await self.middleware_stack(scope, receive, send)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\starlette\middleware\errors.py", line 184, in __call__
    raise exc
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\starlette\middleware\errors.py", line 162, in __call__
    await self.app(scope, receive, _send)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\gradio\route_utils.py", line 724, in __call__
    await self.app(scope, receive, send)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\starlette\middleware\exceptions.py", line 79, in __call__
    raise exc
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\starlette\middleware\exceptions.py", line 68, in __call__
    await self.app(scope, receive, sender)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\fastapi\middleware\asyncexitstack.py", line 20, in __call__
    raise e
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\fastapi\middleware\asyncexitstack.py", line 17, in __call__
    await self.app(scope, receive, send)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\starlette\routing.py", line 718, in __call__
    await route.handle(scope, receive, send)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\starlette\routing.py", line 276, in handle
    await self.app(scope, receive, send)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\starlette\routing.py", line 66, in app
    response = await func(request)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\fastapi\routing.py", line 274, in app
    raw_response = await run_endpoint_function(
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\fastapi\routing.py", line 193, in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\starlette\concurrency.py", line 41, in run_in_threadpool
    return await anyio.to_thread.run_sync(func, *args)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\anyio\to_thread.py", line 33, in run_sync
    return await get_asynclib().run_sync_in_worker_thread(
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\anyio\_backends\_asyncio.py", line 877, in run_sync_in_worker_thread
    return await future
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\system\python\lib\site-packages\anyio\_backends\_asyncio.py", line 807, in run
    result = context.run(func, *args)
  File "F:\03_Gen AI tools\webui_forge_cu121_torch231\webui\modules\progress.py", line 113, in progressapi
    elapsed_since_start = time.time() - shared.state.time_start
TypeError: unsupported operand type(s) for -: 'float' and 'NoneType'
Loading Model: {'checkpoint_info': {'filename': 'F:\\03_Gen AI tools\\webui_forge_cu121_torch231\\webui\\models\\Stable-diffusion\\flux\\flux1DevHyperNF4Flux1DevBNB_flux1DevHyperNF4.safetensors', 'hash': 'a005585e'}, 'additional_modules': [], 'unet_storage_dtype': None}
[Unload] Trying to free all memory for cuda:0 with 0 models keep loaded ... Done.
StateDict Keys: {'transformer': 1722, 'vae': 244, 'text_encoder': 198, 'text_encoder_2': 220, 'ignore': 0}
CLIPTextModel Unexpected: ['transformer.text_model.embeddings.token_embedding.wrapped.weight']
Using Detected T5 Data Type: torch.float8_e4m3fn
Using Detected UNet Type: nf4
Using pre-quant state dict!
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
K-Model Created: {'storage_dtype': 'nf4', 'computation_dtype': torch.bfloat16}
Model loaded in 0.8s (unload existing model: 0.3s, forge model load: 0.6s).
[LORA] Loaded F:\03_Gen AI tools\webui_forge_cu121_torch231\webui\models\Lora\Flux\Detailers\aidmaImageUprader-FLUX-v0.3.safetensors for KModel-UNet with 304 keys at weight 0.94 (skipped 0 keys) with on_the_fly = True
[LORA] Loaded F:\03_Gen AI tools\webui_forge_cu121_torch231\webui\models\Lora\Flux\Artist Styles\Carlos_Nine-5.safetensors for KModel-UNet with 304 keys at weight 0.62 (skipped 0 keys) with on_the_fly = True
Skipping unconditional conditioning when CFG = 1. Negative Prompts are ignored.
[Unload] Trying to free 7986.54 MB for cuda:0 with 0 models keep loaded ... Done.
[Memory Management] Target: JointTextEncoder, Free GPU: 11231.88 MB, Model Require: 5153.49 MB, Previously Loaded: 0.00 MB, Inference Require: 1287.00 MB, Remaining: 4791.38 MB, All loaded to GPU.
Moving model(s) has taken 2.51 seconds